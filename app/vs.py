########################################################################################################################################
# Importing packages
########################################################################################################################################

import streamlit as st
import base64
import warnings
warnings.filterwarnings(action='ignore')

import numpy as np
import pandas as pd
from pandas import DataFrame

from sklearn import metrics
import pickle

from rdkit import Chem
from rdkit.Chem import AllChem, Descriptors, inchi, DataStructs

import matplotlib.pyplot as plt

def app(df, s_state):
    info = {
        "PKL": "A PKL file is a file generated by the pickle method; you can generate it in the machine learning methods in the app or upload one of your own.",
        "CSV": "Awaiting for CSV file to be uploaded.",
        "Modeling": ["Awaiting for Modeling Data file to be uploaded.", "If you have SMILES ***AND*** want to see the molecules: name the column with the SMILES and save the SMILES column"],
        "Links": [
            "https://github.com/joseteofilo/data_qsarlit/blob/master/descriptor_morgan_r2_2048bits_for_modeling.csv",
            "https://github.com/joseteofilo/data_qsarlit/blob/master/descriptor_morgan_r2_2048bits_for_vs.csv",
            "https://github.com/joseteofilo/data_qsarlit/blob/master/model_rf_morgan_r2_2048bits.pkl"
        ]
    }

    ########################################################################################################################################
    # Initialize session state variables
    ########################################################################################################################################
    if 'data_uploaded' not in s_state:
        s_state['data_uploaded'] = False
    if 'model_uploaded' not in s_state:
        s_state['model_uploaded'] = False
    if 'data' not in s_state:
        s_state['data'] = None
    if 'model' not in s_state:
        s_state['model'] = None
    if 'model_type' not in s_state:
        s_state['model_type'] = None
    if 'prob_threshold' not in s_state:
        s_state['prob_threshold'] = 0.5

    ########################################################################################################################################
    # Functions
    ########################################################################################################################################

    def filedownload(df, filename='results.csv'):
        csv = df.to_csv(index=False)
        b64 = base64.b64encode(csv.encode()).decode()  # strings <-> bytes conversions
        href = f'<a href="data:file/csv;base64,{b64}" download="{filename}">Download CSV File</a>'
        st.markdown(href, unsafe_allow_html=True)

    def remove_duplicates(df, smiles_col):
        # Compute InChIKeys to identify duplicates
        mols = df[smiles_col].apply(Chem.MolFromSmiles)
        inchikeys = mols.apply(lambda mol: inchi.MolToInchiKey(mol) if mol is not None else None)
        df['InChIKey'] = inchikeys
        df_nodup = df.drop_duplicates(subset='InChIKey')
        df_nodup = df_nodup.dropna(subset=['InChIKey'])
        df_nodup = df_nodup.drop(columns=['InChIKey'])
        return df_nodup

    def standardize_smiles(df, smiles_col):
        # Ensure the SMILES column is of type string
        df[smiles_col] = df[smiles_col].astype(str)
        # Handle missing or invalid SMILES entries
        def sanitize_smiles(smiles):
            try:
                mol = Chem.MolFromSmiles(smiles)
                if mol is not None:
                    return Chem.MolToSmiles(mol, canonical=True)
                else:
                    return None
            except:
                return None
        df[smiles_col] = df[smiles_col].apply(sanitize_smiles)
        # Remove rows where SMILES could not be parsed
        df = df.dropna(subset=[smiles_col])
        return df

    def compute_ecfp(df, smiles_col, nBits=1024):
        # Compute ECFP fingerprints with specified nBits
        mols = df[smiles_col].apply(Chem.MolFromSmiles)
        # Handle invalid molecules
        valid_indices = mols.notnull()
        mols = mols[valid_indices]
        df = df[valid_indices]
        fps = mols.apply(lambda mol: AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=nBits))
        fp_array = np.array([np.zeros((nBits,), dtype=int)] * len(fps))
        for i, fp in enumerate(fps):
            arr = np.zeros((nBits,), dtype=int)
            DataStructs.ConvertToNumpyArray(fp, arr)
            fp_array[i] = arr
        fp_df = pd.DataFrame(fp_array)
        return df.reset_index(drop=True), fp_df.reset_index(drop=True)

    def plot_metrics(metrics_dict):
        fig, ax = plt.subplots()
        ax.bar(metrics_dict.keys(), metrics_dict.values())
        st.pyplot(fig)

    ########################################################################################################################################
    # Sidebar - Upload data
    ########################################################################################################################################
    st.sidebar.header('1. Upload your dataset')
    if not s_state['data_uploaded']:
        uploaded_file = st.sidebar.file_uploader("Upload your CSV data", type=['csv'], key='data_upload')
        if uploaded_file is not None:
            s_state['data'] = pd.read_csv(uploaded_file)
            s_state['data_uploaded'] = True
            st.sidebar.success('Data uploaded successfully')
    else:
        st.sidebar.write('Data already uploaded')

    ########################################################################################################################################
    # Sidebar - Select SMILES column
    ########################################################################################################################################
    if s_state['data_uploaded']:
        s_state['smiles_col'] = st.sidebar.selectbox('Select the column containing SMILES', s_state['data'].columns)
    else:
        s_state['smiles_col'] = None

    ########################################################################################################################################
    # Sidebar - Upload model
    ########################################################################################################################################
    st.sidebar.header('2. Upload your model (PKL file)')
    if not s_state['model_uploaded']:
        uploaded_model_file = st.sidebar.file_uploader("Upload your model PKL file", type=['pkl'], key='model_file_upload')
        if uploaded_model_file is not None:
            s_state['model'] = pickle.load(uploaded_model_file)
            s_state['model_uploaded'] = True
            st.sidebar.success('Model uploaded successfully')
    else:
        st.sidebar.write('Model already uploaded')

    ########################################################################################################################################
    # Sidebar - Select model type
    ########################################################################################################################################
    if s_state['model_uploaded']:
        s_state['model_type'] = st.sidebar.selectbox('Select model type', ['Regression', 'Classification'])
    else:
        s_state['model_type'] = None

    ########################################################################################################################################
    # Sidebar - Probability Threshold (for classification)
    ########################################################################################################################################
    if s_state.get('model_type') == 'Classification':
        s_state['prob_threshold'] = st.sidebar.number_input('Enter the Probability Threshold', min_value=0.0, max_value=1.0, value=0.5)

    ########################################################################################################################################
    # Run button
    ########################################################################################################################################
    if st.sidebar.button('Run', key='run_button'):
        if s_state['data_uploaded'] and s_state['model_uploaded'] and s_state['smiles_col'] is not None and s_state['model_type'] is not None:
            # Data curation steps
            data = s_state['data'].copy()
            smiles_col = s_state['smiles_col']

            # Standardize SMILES
            data = standardize_smiles(data, smiles_col)

            # Remove duplicates
            data = remove_duplicates(data, smiles_col)

            # Remove missing data
            data = data.dropna(subset=[smiles_col])

            # Determine number of features expected by the model
            model = s_state['model']
            try:
                n_features = model.n_features_in_
                st.write(f"Model expects {n_features} features.")
            except AttributeError:
                # If n_features_in_ is not available, default to 2048 or ask the user
                st.warning("Could not determine the number of features from the model. Please input the number of bits used for fingerprints.")
                n_features = st.number_input('Enter number of bits used in model fingerprints (e.g., 1024 or 2048)', min_value=1, value=2048)
            except Exception as e:
                st.error(f"An error occurred: {e}")
                return

            # Compute ECFP fingerprints
            data, fp_df = compute_ecfp(data, smiles_col, nBits=n_features)

            # Check if fp_df is empty
            if fp_df.empty:
                st.error('No valid molecules found after processing. Please check your SMILES data.')
                return

            # Applicability Domain Calculation
            # Check if the model includes descriptor_min and descriptor_max
            if hasattr(model, 'descriptor_min') and hasattr(model, 'descriptor_max'):
                descriptor_min = model.descriptor_min
                descriptor_max = model.descriptor_max

                # Check if the lengths match
                if len(descriptor_min) != n_features or len(descriptor_max) != n_features:
                    st.error('Descriptor min/max lengths do not match the number of features expected by the model.')
                    return

                # Convert descriptor_min and descriptor_max to numpy arrays
                descriptor_min = np.array(descriptor_min)
                descriptor_max = np.array(descriptor_max)

                # Check if each descriptor is within the min-max range
                within_min = fp_df.values >= descriptor_min
                within_max = fp_df.values <= descriptor_max
                within_ad = within_min & within_max
                inside_ad = within_ad.all(axis=1)
                data['AD'] = np.where(inside_ad, 'Inside', 'Outside')

                # Calculate percentage of molecules inside and outside the AD
                total_samples = len(data)
                inside_count = data['AD'].value_counts().get('Inside', 0)
                outside_count = data['AD'].value_counts().get('Outside', 0)
                inside_percentage = (inside_count / total_samples) * 100
                outside_percentage = (outside_count / total_samples) * 100
                st.write(f"Percentage of molecules inside the applicability domain: {inside_percentage:.2f}%")
                st.write(f"Percentage of molecules outside the applicability domain: {outside_percentage:.2f}%")
            else:
                st.warning('Model does not include applicability domain information. Applicability domain calculations cannot be performed.')
                data['AD'] = 'Unknown'

            # Prediction
            if s_state['model_type'] == 'Regression':
                try:
                    y_pred = model.predict(fp_df)
                    data['Prediction'] = y_pred
                except Exception as e:
                    st.error(f"An error occurred during prediction: {e}")
                    return

                # Metrics (assuming true values are available in 'Actual' column)
                if 'Actual' in data.columns:
                    y_true = data['Actual']
                    mse = metrics.mean_squared_error(y_true, y_pred)
                    r2 = metrics.r2_score(y_true, y_pred)
                    st.header('**Metrics**')
                    st.write(f'Mean Squared Error (MSE): {mse}')
                    st.write(f'R-squared (R2): {r2}')
                    # Plotting
                    fig, ax = plt.subplots()
                    ax.scatter(y_true, y_pred)
                    ax.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'k--', lw=2)
                    ax.set_xlabel('Actual')
                    ax.set_ylabel('Predicted')
                    st.pyplot(fig)
                else:
                    st.info('Actual values not provided; metrics cannot be calculated.')

                # Display predictions
                st.header('**Predictions**')
                st.write(data)

                # Download predictions
                filedownload(data, filename='predictions.csv')

            elif s_state['model_type'] == 'Classification':
                try:
                    if hasattr(model, 'predict_proba'):
                        y_proba = model.predict_proba(fp_df)[:, 1]
                        y_pred = (y_proba >= s_state['prob_threshold']).astype(int)
                        data['Probability'] = y_proba
                    else:
                        # If the model doesn't support predict_proba
                        y_pred = model.predict(fp_df)
                        data['Probability'] = None
                    data['Prediction'] = y_pred
                except Exception as e:
                    st.error(f"An error occurred during prediction: {e}")
                    return

                # Metrics (assuming true labels are available in 'Actual' column)
                if 'Actual' in data.columns:
                    y_true = data['Actual']
                    if data['Probability'].isnull().all():
                        accuracy = metrics.accuracy_score(y_true, y_pred)
                        st.header('**Metrics**')
                        st.write(f'Accuracy: {accuracy}')
                    else:
                        accuracy = metrics.accuracy_score(y_true, y_pred)
                        roc_auc = metrics.roc_auc_score(y_true, data['Probability'])
                        st.header('**Metrics**')
                        st.write(f'Accuracy: {accuracy}')
                        st.write(f'ROC AUC: {roc_auc}')
                        # Plotting ROC Curve
                        fpr, tpr, thresholds = metrics.roc_curve(y_true, data['Probability'])
                        fig, ax = plt.subplots()
                        ax.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)
                        ax.plot([0, 1], [0, 1], 'k--')
                        ax.set_xlabel('False Positive Rate')
                        ax.set_ylabel('True Positive Rate')
                        ax.set_title('Receiver Operating Characteristic')
                        ax.legend(loc='lower right')
                        st.pyplot(fig)
                else:
                    st.info('Actual labels not provided; metrics cannot be calculated.')

                # Display predictions
                st.header('**Predictions**')
                st.write(data)

                # Download predictions
                filedownload(data, filename='predictions.csv')

            else:
                st.error('Invalid model type selected.')

        else:
            st.error('Please upload data, select the SMILES column, upload a model, and select the model type before running.')

    ########################################################################################################################################
    # Display data (if any)
    ########################################################################################################################################
    if s_state['data_uploaded']:
        st.header('**Uploaded Data Preview**')
        st.write(s_state['data'].head())

# Run the app
if __name__ == '__main__':
    # Initialize session state if not already done
    if 'session_state' not in st.session_state:
        st.session_state.session_state = {}
    # Replace `df` with your actual DataFrame if you have one at startup, or pass `None`
    df = None  # Or your actual DataFrame
    app(df, st.session_state.session_state)
